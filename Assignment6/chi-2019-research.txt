# Work Distribution: The RotoSwype paper was read and then summarized by both team members together. 
# The i's Free paper was read and summarized by Andreas Pfaffelhuber, the VelociWatch paper by Daniel Schmaderer. 
RotoSwype: Word-Gesture Typing using a Ring

Gupta, Ji, Yeo, Quigley and Vogel (2019) invented the RotoSwype, a technique for word-gesture typing that uses the orientation of a ring worn on the index finger by translating the rings rotation or his angular movement to a x-y position of a pointer on a virtual keyboard which may be presented in a VR or AR environment. The user enters a word by pressing the button on the ring when moved over the starting letter of his word, and then drives over all the letters contained in it by rotating the ring, before he presses the button again to signal that his input is done. RotoSwype then presents suggested words of which the user can select one and offers a way to delete words by holding the ring button for a longer period of time. Gupta, Ji, Yeo, Quigley and Vogel (2019) then tested their prototype for arm postures with hand-up and hand-down, where hand-up also was tested for palm to the ground and palm to the side conditions. Their results showed for both tested conditions that users outperformed existing one handed-techniques as long as they consecutively typed for no longer than 60 minutes (with a typing rate of more than 14 words per minute and an uncorrected error rate of less than one percent), and that the input speed was significantly higher using palm to the ground instead of palm to the side.

Gupta, A., Ji, C., Yeo, H. S., Quigley, A. J., & Vogel, D. (2019, May). RotoSwype: word-gesture typing using a ring. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI'19). ACM.


i’sFree:Eyes-FreeGestureTypingviaa Touch-EnabledRemoteControl

Zhu, Zheng, Zhai and Bi (2019) wrote a paper to present i’sFree, which allows for eyes-free gesture typing on a distant display by using a touch-enabled remote control. It does not display any text or gesture trace and instead uses an invisible but shifting QWERTY-Keyboard to capture user inputs. To develop i’sFree, they first performed a user study to investigate eyes-free typing behaviour and found that while there were large key position variances caused by the unknown vertical position of the keyboard, there was also a small keyboard position offset from previous gesture. Based on those findings they designed a decoder that learns from input gestures to dynamically adjust the keyboard location, which’s decoding algorithm has two components, a language model that provides a prior probability of a word based on the context, and a spatial model that provides the likelihood of the gesture distribution for a given word. They then evaluated i’sFree through another user study and found that it was an easy to learn input method where even completely unfamiliar subjects managed to have a decent input speed, and that it heavily outperformed the eyes-free baseline with a regular gesture typing decoder.

Zhu, S., Zheng, J., Zhai, S., & Bi, X. (2019, April). i'sFree: Eyes-Free Gesture Typing via a Touch-Enabled Remote Control. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (p. 448). ACM.



VelociWatch: Designing and Evaluating a Virtual Keyboard for the Input of Challenging Text

In the VelociWatch paper (Vertanen, Gaines, Fletcher, Stanage, Watling, Kristensson, … & Kuhl, 2019), its authors investigated whether users can guess which words are likely to cause problems for auto-correction and whether they thus might be able to adjust their behaviour to assist the decoder. They created a phrase set with difficult text for normal auto completion and found that users are able to tell which will likely be problematic for a virtual keyboard decoder. They then compared 135 keyboard designs in computational experiments and compared tap and swipe selection of small touchscreen targets to find out that both perform similarly. Based on their findings, they designed a predictive virtual keyboard named VelociWatch based on the findings of their first experiments, which offers five suggestions as well as a backspace button and uses swipe selection to select one of the possibilities since that was deemed most appropriate for a smartwatch. They then evaluated their VelociWatch, and found that while users were able to enter challenging text at 17 words per minute with a corrected error rate of 3%, they still wrote a bit faster and just as accurately on a simpler keyboard with limited correction options.

Vertanen, K., Gaines, D., Fletcher, C., Stanage, A. M., Watling, R., Kristensson, P. O., ... & Kuhl, S. (2019, April). VelociWatch: Designing and Evaluating a Virtual Keyboard for the Input of Challenging Text. In CHI (p. 591).

